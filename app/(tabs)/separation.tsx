import React, { useState, useEffect } from 'react';
import {
  View,
  Text,
  StyleSheet,
  TouchableOpacity,
  ScrollView,
  Platform,
  Alert,
} from 'react-native';
import { Audio } from 'expo-av';
import { LinearGradient } from 'expo-linear-gradient';
import {
  Music,
  Mic,
  Volume2,
  VolumeX,
  Download,
  Play,
  Pause,
  Layers,
  AlertCircle,
} from 'lucide-react-native';
import { TrackSeparationView } from '../../components/TrackSeparationView';
import { SeparationProgress } from '../../components/SeparationProgress';
import { WaveformView } from '../../components/WaveformView';
import { useAudio } from '../../contexts/AudioContext';
import {
  realAISeparationService,
  SeparationProgress as SeparationProgressType,
} from '../../services/RealAISeparationService';
import { freeAISeparationService } from '../../services/FreeAISeparationService';

interface SeparatedTrack {
  id: string;
  name: string;
  icon: any;
  volume: number;
  isMuted: boolean;
  color: string;
  sound: Audio.Sound | null;
}

interface PlaybackStatus {
  isLoaded: boolean;
  isPlaying: boolean;
  position: number;
  duration: number;
  volume: number;
}

export default function SeparationScreen() {
  const {
    audioUri,
    currentSong,
    sound: mainSound,
    separatedTracks: globalSeparatedTracks,
    setSeparatedTracks: setGlobalSeparatedTracks,
  } = useAudio();

  const [tracks, setTracks] = useState<SeparatedTrack[]>([
    {
      id: 'vocals',
      name: 'Vocals',
      icon: Mic,
      volume: 1.0,
      isMuted: false,
      color: '#EF4444',
      sound: null,
    },
    {
      id: 'instrumental',
      name: 'Instrumental',
      icon: Music,
      volume: 0.0,
      isMuted: false,
      color: '#3B82F6',
      sound: null,
    },
    {
      id: 'drums',
      name: 'Drums',
      icon: Music,
      volume: 0.0,
      isMuted: false,
      color: '#F59E0B',
      sound: null,
    },
    {
      id: 'bass',
      name: 'Bass',
      icon: Music,
      volume: 0.0,
      isMuted: false,
      color: '#10B981',
      sound: null,
    },
    {
      id: 'other',
      name: 'Other',
      icon: Music,
      volume: 0.0,
      isMuted: false,
      color: '#8B5CF6',
      sound: null,
    },
  ]);

  const [isProcessing, setIsProcessing] = useState(false);
  const [processingProgress, setProcessingProgress] = useState(0);
  const [separationComplete, setSeparationComplete] = useState(false);
  const [isPlaying, setIsPlaying] = useState(false);
  const [position, setPosition] = useState(0);
  const [duration, setDuration] = useState(0);
  const [playbackUpdateInterval, setPlaybackUpdateInterval] =
    useState<NodeJS.Timeout | null>(null);

  useEffect(() => {
    // Stop main audio when entering separation tab
    const stopMainAudio = async () => {
      if (mainSound) {
        try {
          await mainSound.pauseAsync();
        } catch (error) {
          console.error('Error stopping main audio:', error);
        }
      }
    };

    stopMainAudio();

    // Initialize audio mode for multiple tracks
    const initializeAudio = async () => {
      try {
        await Audio.setAudioModeAsync({
          allowsRecordingIOS: false,
          staysActiveInBackground: true,
          playsInSilentModeIOS: true,
          shouldDuckAndroid: true,
          playThroughEarpieceAndroid: false,
        });
      } catch (error) {
        console.error('Error setting audio mode:', error);
      }
    };

    initializeAudio();

    // Cleanup interval on unmount
    return () => {
      if (playbackUpdateInterval) {
        clearInterval(playbackUpdateInterval);
      }
    };
  }, [mainSound]);

  // Sync local tracks with global separated tracks
  useEffect(() => {
    if (tracks.length > 0 && tracks.some((t) => t.sound)) {
      const globalTracks = tracks.map((track) => ({
        id: track.id,
        name: track.name,
        sound: track.sound,
        volume: track.volume,
        isMuted: track.isMuted,
      }));
      setGlobalSeparatedTracks(globalTracks);
    }
  }, [tracks, setGlobalSeparatedTracks]);

  // Update playback status from tracks
  useEffect(() => {
    if (separationComplete && tracks.some((t) => t.sound)) {
      const updatePlaybackStatus = async () => {
        try {
          // Get status from the first active track
          const activeTrack = tracks.find((t) => t.sound && !t.isMuted);
          if (activeTrack?.sound) {
            const status = await activeTrack.sound.getStatusAsync();
            if (status.isLoaded) {
              setPosition(status.positionMillis || 0);
              setDuration(status.durationMillis || 0);
              setIsPlaying(status.isPlaying || false);
            }
          }
        } catch (error) {
          console.error('Error updating playback status:', error);
        }
      };

      // Update every 100ms when playing
      if (isPlaying) {
        const interval = setInterval(updatePlaybackStatus, 100);
        setPlaybackUpdateInterval(interval);
        return () => clearInterval(interval);
      } else {
        if (playbackUpdateInterval) {
          clearInterval(playbackUpdateInterval);
          setPlaybackUpdateInterval(null);
        }
      }
    }
  }, [isPlaying, separationComplete, tracks]);

  const startSeparation = async () => {
    if (!audioUri) {
      Alert.alert(
        'No Audio',
        'Please load an audio file in the Player tab first'
      );
      return;
    }

    setIsProcessing(true);
    setProcessingProgress(0);
    setSeparationComplete(false);

    try {
      Alert.alert(
        'FREE AI Separation',
        'This will separate your audio using FREE AI models:\n\n1. Local backend (if running)\n   â€¢ Simple demo: python backend/app-simple.py\n   â€¢ Full AI: python backend/app.py\n2. Free cloud AI services (fallback)\n\nEach track will contain isolated audio elements - completely FREE!',
        [
          {
            text: 'Cancel',
            style: 'cancel',
            onPress: () => setIsProcessing(false),
          },
          { text: 'Continue', onPress: () => performRealSeparation() },
        ]
      );
    } catch (error) {
      console.error('Setup failed:', error);
      setIsProcessing(false);
    }
  };

  const performRealSeparation = async () => {
    try {
      // Try the local backend first (completely free)
      let separatedTracks;
      try {
        separatedTracks = await realAISeparationService.separateAudio(
          audioUri!,
          (progress: SeparationProgressType) => {
            setProcessingProgress(progress.progress);
          }
        );
      } catch (backendError) {
        console.log('Local backend not available, trying free AI services...');

        // Fallback to free AI services
        separatedTracks = await freeAISeparationService.separateAudio(
          audioUri!,
          {
            model: 'demucs',
            quality: 'high',
            stems: ['vocals', 'drums', 'bass', 'other'],
          },
          (progress) => {
            setProcessingProgress(progress.progress);
          }
        );
      }

      // Create Audio.Sound objects for each separated track
      const updatedTracks = await Promise.all(
        tracks.map(async (track) => {
          let trackUri: string | undefined;

          if (track.id === 'vocals') {
            trackUri = separatedTracks.vocals;
          } else if (track.id === 'drums') {
            trackUri = separatedTracks.drums;
          } else if (track.id === 'bass') {
            trackUri = separatedTracks.bass;
          } else if (track.id === 'instrumental') {
            trackUri = separatedTracks.instrumental;
          } else if (track.id === 'other') {
            trackUri = separatedTracks.other;
          }

          if (trackUri) {
            try {
              const { sound } = await Audio.Sound.createAsync(
                { uri: trackUri },
                {
                  shouldPlay: false,
                  volume: track.volume,
                  isLooping: false,
                }
              );

              // Set up status update listener for each track
              sound.setOnPlaybackStatusUpdate((status: any) => {
                if (status.isLoaded) {
                  // Sync all tracks to same position
                  if (Math.abs((status.positionMillis || 0) - position) > 200) {
                    // Only update if significantly different to avoid loops
                    setPosition(status.positionMillis || 0);
                  }
                }
              });

              return { ...track, sound };
            } catch (error) {
              console.error(`Error loading ${track.name} track:`, error);
              return track;
            }
          }
          return track;
        })
      );

      setTracks(updatedTracks);
      setSeparationComplete(true);
      Alert.alert(
        'FREE AI separation complete! ðŸŽ‰',
        'Your audio has been processed with FREE AI models! Each track contains truly separated audio elements. Mix them independently for professional results!'
      );
    } catch (error) {
      console.error('Vocal isolation failed:', error);
      const errorMessage =
        error instanceof Error ? error.message : 'Unknown error occurred';
      Alert.alert(
        'FREE AI Separation Failed',
        `AI separation failed: ${errorMessage}\n\nQuick start options:\nâ€¢ Try simple demo: python backend/app-simple.py\nâ€¢ Or full AI: python backend/app.py\nâ€¢ Check http://localhost:5000/health\nâ€¢ Use supported audio formats (MP3/WAV)`,
        [{ text: 'OK', style: 'cancel' }]
      );
    } finally {
      setIsProcessing(false);
    }
  };

  const playPause = async () => {
    try {
      // Prevent multiple calls
      if (isPlaying === undefined) return;

      const newPlayingState = !isPlaying;
      setIsPlaying(newPlayingState);

      if (newPlayingState) {
        // Play all tracks, but with correct volume (0 for muted, actual volume for unmuted)
        const playPromises = tracks
          .filter((track) => track.sound)
          .map(async (track) => {
            if (track.sound) {
              await track.sound.setPositionAsync(position);
              // Set volume based on mute state before playing
              const volume = track.isMuted ? 0 : track.volume;
              await track.sound.setVolumeAsync(volume);
              return track.sound.playAsync();
            }
          });

        await Promise.all(playPromises);
      } else {
        // Pause all tracks
        const pausePromises = tracks
          .filter((track) => track.sound)
          .map((track) => track.sound?.pauseAsync());

        await Promise.all(pausePromises);
      }
    } catch (error) {
      console.error('Error playing/pausing tracks:', error);
      setIsPlaying(!isPlaying); // Revert state on error
    }
  };

  const seek = async (newPosition: number) => {
    try {
      setPosition(newPosition);
      // Sync all tracks to the new position
      const seekPromises = tracks
        .filter((track) => track.sound)
        .map((track) => track.sound?.setPositionAsync(newPosition));

      await Promise.all(seekPromises);
    } catch (error) {
      console.error('Error seeking:', error);
    }
  };

  const updateTrackVolume = async (trackId: string, volume: number) => {
    setTracks((prev) =>
      prev.map((track) => {
        if (track.id === trackId) {
          if (track.sound) {
            track.sound.setVolumeAsync(volume);
          }
          return { ...track, volume };
        }
        return track;
      })
    );
  };

  const toggleMute = async (trackId: string) => {
    setTracks((prev) =>
      prev.map((track) => {
        if (track.id === trackId) {
          const newMuted = !track.isMuted;
          if (track.sound) {
            // Just change volume, don't start/stop playback
            if (newMuted) {
              track.sound.setVolumeAsync(0);
            } else {
              track.sound.setVolumeAsync(track.volume);
            }
          }
          return { ...track, isMuted: newMuted };
        }
        return track;
      })
    );
  };
  const downloadTrack = async (trackId: string) => {
    try {
      Alert.alert('Download', `Downloading ${trackId} track...`);
      // Mock download implementation
      setTimeout(() => {
        Alert.alert('Success', `${trackId} track downloaded successfully!`);
      }, 1500);
    } catch (error) {
      console.error('Download failed:', error);
      Alert.alert('Error', 'Failed to download track');
    }
  };

  const formatTime = (milliseconds: number) => {
    const minutes = Math.floor(milliseconds / 60000);
    const seconds = Math.floor((milliseconds % 60000) / 1000);
    return `${minutes}:${seconds.toString().padStart(2, '0')}`;
  };

  return (
    <LinearGradient
      colors={['#1F2937', '#111827', '#000000']}
      style={styles.container}
    >
      <View style={styles.header}>
        <Layers size={32} color="#8B5CF6" />
        <Text style={styles.title}>Track Separation</Text>
      </View>

      {!audioUri ? (
        <View style={styles.noAudioContainer}>
          <AlertCircle size={64} color="#6B7280" />
          <Text style={styles.noAudioTitle}>No Audio Loaded</Text>
          <Text style={styles.noAudioDescription}>
            Please load an audio file in the Player tab first to use track
            separation
          </Text>
        </View>
      ) : !separationComplete ? (
        <View style={styles.setupContainer}>
          <Text style={styles.setupTitle}>
            ðŸ†“ FREE AI Music Source Separation
          </Text>
          <Text style={styles.setupDescription}>
            Current song: {currentSong}
          </Text>
          <Text style={styles.setupDescription}>
            ðŸš€ Using Spleeter AI models to separate your music into:
          </Text>
          <Text style={styles.setupDescription}>
            â€¢ Pure vocals track{'\n'}â€¢ Isolated drums track{'\n'}â€¢ Clean bass
            track{'\n'}â€¢ Other instruments track
          </Text>
          <Text style={styles.setupDescription}>
            âš¡ Processing time: 1-2 minutes{'\n'}ðŸ’° Cost: Completely FREE!
            {'\n'}ðŸŽ¯ Accuracy: Professional-grade AI separation{'\n'}ðŸ¤– Backend
            options: Simple demo or full AI{'\n'}ðŸ”„ Auto-fallback: Uses best
            available option
          </Text>

          {!isProcessing ? (
            <TouchableOpacity
              style={styles.startButton}
              onPress={startSeparation}
            >
              <Layers size={20} color="#FFFFFF" />
              <Text style={styles.startButtonText}>
                Start FREE AI Separation
              </Text>
            </TouchableOpacity>
          ) : (
            <SeparationProgress progress={processingProgress} />
          )}
        </View>
      ) : (
        <ScrollView
          style={styles.tracksContainer}
          showsVerticalScrollIndicator={false}
        >
          <View style={styles.playerSection}>
            <Text style={styles.sectionTitle}>Now Playing: {currentSong}</Text>

            <WaveformView
              duration={duration}
              position={position}
              onSeek={seek}
            />

            <View style={styles.timeContainer}>
              <Text style={styles.timeText}>{formatTime(position)}</Text>
              <Text style={styles.timeText}>{formatTime(duration)}</Text>
            </View>

            <View style={styles.mainControls}>
              <TouchableOpacity style={styles.playButton} onPress={playPause}>
                {isPlaying ? (
                  <Pause size={32} color="#FFFFFF" />
                ) : (
                  <Play size={32} color="#FFFFFF" />
                )}
              </TouchableOpacity>
            </View>

            <View style={styles.demoNotice}>
              <AlertCircle size={16} color="#10B981" />
              <Text style={styles.demoText}>
                FREE AI: All tracks use real Spleeter AI separation. Completely
                free to use with your local Python backend!
              </Text>
            </View>
          </View>

          <Text style={styles.sectionTitle}>Individual Track Controls</Text>

          <View style={styles.infoContainer}>
            <Text style={styles.infoText}>
              ðŸ’¡ <Text style={styles.infoBold}>How it works:</Text> Each track
              contains AI-separated audio elements using FREE Spleeter models.
              Mix and match different tracks to create your perfect sound.
              Adjust volumes independently for creative control - all completely
              FREE!
            </Text>
          </View>

          {tracks.map((track) => (
            <TrackSeparationView
              key={track.id}
              track={{
                ...track,
                isProcessing: false,
              }}
              onVolumeChange={(volume) => updateTrackVolume(track.id, volume)}
              onToggleMute={() => toggleMute(track.id)}
              onDownload={() => downloadTrack(track.id)}
            />
          ))}

          <View style={styles.masterControls}>
            <TouchableOpacity
              style={styles.masterButton}
              onPress={() => {
                tracks.forEach((track) => {
                  if (track.id !== 'vocals') {
                    toggleMute(track.id);
                  }
                });
              }}
            >
              <Text style={styles.masterButtonText}>Vocals Only</Text>
            </TouchableOpacity>
            <TouchableOpacity
              style={styles.masterButton}
              onPress={() => {
                tracks.forEach((track) => {
                  if (track.id === 'drums') {
                    toggleMute(track.id);
                  }
                });
              }}
            >
              <Text style={styles.masterButtonText}>Toggle Drums</Text>
            </TouchableOpacity>
          </View>
        </ScrollView>
      )}
    </LinearGradient>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    paddingTop: Platform.OS === 'ios' ? 60 : 40,
  },
  header: {
    flexDirection: 'row',
    alignItems: 'center',
    paddingHorizontal: 20,
    marginBottom: 30,
  },
  title: {
    fontSize: 28,
    fontWeight: 'bold',
    color: '#FFFFFF',
    marginLeft: 12,
  },
  noAudioContainer: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
    paddingHorizontal: 40,
  },
  noAudioTitle: {
    fontSize: 24,
    fontWeight: 'bold',
    color: '#FFFFFF',
    textAlign: 'center',
    marginTop: 20,
    marginBottom: 16,
  },
  noAudioDescription: {
    fontSize: 16,
    color: '#9CA3AF',
    textAlign: 'center',
    lineHeight: 24,
  },
  setupContainer: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
    paddingHorizontal: 40,
  },
  setupTitle: {
    fontSize: 24,
    fontWeight: 'bold',
    color: '#FFFFFF',
    textAlign: 'center',
    marginBottom: 16,
  },
  setupDescription: {
    fontSize: 16,
    color: '#9CA3AF',
    textAlign: 'center',
    marginBottom: 20,
    lineHeight: 24,
  },
  startButton: {
    flexDirection: 'row',
    alignItems: 'center',
    justifyContent: 'center',
    backgroundColor: '#10B981',
    paddingHorizontal: 40,
    paddingVertical: 16,
    borderRadius: 25,
    gap: 8,
    marginTop: 20,
  },
  startButtonText: {
    color: '#FFFFFF',
    fontSize: 18,
    fontWeight: '600',
  },
  tracksContainer: {
    flex: 1,
    paddingHorizontal: 20,
  },
  playerSection: {
    backgroundColor: 'rgba(139, 92, 246, 0.1)',
    borderRadius: 16,
    padding: 20,
    marginBottom: 30,
    borderWidth: 1,
    borderColor: 'rgba(139, 92, 246, 0.3)',
  },
  demoNotice: {
    flexDirection: 'row',
    alignItems: 'center',
    backgroundColor: 'rgba(16, 185, 129, 0.1)',
    padding: 12,
    borderRadius: 8,
    marginTop: 16,
    gap: 8,
  },
  demoText: {
    flex: 1,
    color: '#10B981',
    fontSize: 12,
    lineHeight: 16,
  },
  mainControls: {
    flexDirection: 'row',
    justifyContent: 'center',
    alignItems: 'center',
    marginVertical: 20,
  },
  playButton: {
    backgroundColor: '#8B5CF6',
    width: 80,
    height: 80,
    borderRadius: 40,
    justifyContent: 'center',
    alignItems: 'center',
  },
  timeContainer: {
    flexDirection: 'row',
    justifyContent: 'space-between',
    marginTop: 16,
  },
  timeText: {
    color: '#9CA3AF',
    fontSize: 14,
    fontWeight: '500',
  },
  sectionTitle: {
    fontSize: 20,
    fontWeight: 'bold',
    color: '#FFFFFF',
    marginBottom: 20,
  },
  masterControls: {
    flexDirection: 'row',
    justifyContent: 'space-around',
    marginTop: 30,
    marginBottom: 40,
  },
  masterButton: {
    backgroundColor: 'rgba(139, 92, 246, 0.2)',
    paddingHorizontal: 20,
    paddingVertical: 12,
    borderRadius: 20,
    borderWidth: 1,
    borderColor: '#8B5CF6',
  },
  masterButtonText: {
    color: '#8B5CF6',
    fontSize: 14,
    fontWeight: '600',
  },
  infoContainer: {
    backgroundColor: 'rgba(139, 92, 246, 0.1)',
    padding: 16,
    borderRadius: 12,
    marginBottom: 20,
    borderWidth: 1,
    borderColor: 'rgba(139, 92, 246, 0.2)',
  },
  infoText: {
    color: '#9CA3AF',
    fontSize: 14,
    lineHeight: 20,
  },
  infoBold: {
    fontWeight: '600',
    color: '#FFFFFF',
  },
});
